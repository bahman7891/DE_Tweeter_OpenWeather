#!/usr/bin/env python

import pandas as pd
import plotly as py
import plotly.graph_objs as go

from boto.s3.connection import S3Connection


def address_extraction(conn,bucket_name):
#'''
#    exctracts the address of the CSV file generated by core computational code.
#    iput: 
#    conn :  S3Connection instant
#    bucket_name: name of the AWS S3 bucket where the data is stored.
#'''
    website_bucket = conn.get_bucket(bucket_name)
    key_name = [key.key for key in website_bucket.list() if '.csv' in key.key]
    address_list = []
    for i,key in enumerate(key_name):
        address_list.append('https://s3.amazonaws.com/'+bucket_name+'/'+str(key))

    return address_list



def data_frames(col_name_list,address_list):
#'''
#
#    input: 
#        col_name_list : names of the columns of the CSV data to be read into pandas dataframe.
#        address_list : the address of the CSV files.
#    returns: list of pandas dataframes.
#'''
    dfs = []
    for i,address in enumerate(address_list):
        print i,address
        dfs.append(pd.read_csv(address,names = col_name_list[i]))
    return dfs



def html_make(dfs,cols):
#'''
#    iput: list of data frames to be displayed.
#    retunr: html page containing the datarames and the plotly link to the visualization of some of the data.
#'''
    df_cnd = dfs[1]
    data = [go.Bar(x=df_cnd[cols[0]],y=df_cnd[cols[1]])]
    url = py.plotly.plot(data,filename='cnd_pol')
    html = '<!DOCTYPE html><HEAD><TITLE>Climate and Tweets!</TITLE></HEAD><BODY>\
    <h4> This is the first launch of our attempt to predict the tweet sentiment based on the\
    weather condition!</h4>\
            {}{}'.format(dfs[0].to_html(),dfs[1].to_html())
    html = html +'<iframe width="800" height="600" frameborder="0" scrolling="no" src="{}.embed" align="middle"></iframe></BODY></HTML>'.format(url)
    return html


if __name__ == "__main__":

    conn = S3Connection()
    address_list = address_extraction(conn,'climsentdata')
    col_names = [['cloudiness','polarity'],['condition','polarity']]
    dfs = data_frames(col_names,address_list)

    html = html_make(dfs,col_names[1])
    website_bucket = conn.get_bucket('climsentpublish')
    output_file = website_bucket.new_key('cld_df_html.html')
    output_file.content_type = 'text/html'
    output_file.set_contents_from_string(html, policy='public-read');


